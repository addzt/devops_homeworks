# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

---

Для начала необходимо просмотреть все текущие операции/запросы командой `db.currentOp()`.  
Каждая операция имеет свой уникальный идентификатор opid, который может быть использоваться для завершения данной операции с помощью команды `db.killOP()`.  
Отследить долгие операции, например, выполняющиеся больше секунды:  
`db.currentOp({"active": true, "secs_running": {"$gt": 1}})`

Чтобы выявить проблемные запросы в MongoDB:

Изучите логи. Особое внимание обратите на:  
Для операций чтения — на поле `responseLength` (в логах отображается как `reslen`).  
Для операций записи — на количество затронутых документов.  
В логах кластера они выводятся в полях `nModified`, `keysInserted`, `keysDeleted`.  
На странице мониторинга кластера изучите графики `Documents affected on primary`, `Documents affected on secondaries`, `Documents affected per host`.  
Изучите данные профилировщика. Выведите долго выполняемые запросы (регулируется настройкой СУБД `slowOpThreshold`).

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
 
---

Redis имеет механизм очистки устаревших ключей. Если текущее количество истекших ключей будет более чем 25%, то Redis заблокирует очистку до того момента, пока не понизит это значение до `<=25%`. Операция очистки запускается каждые 100 миллисекунд.

## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

---


Распространенными причинами являются превышение времени ожидания (`read_timeout`, `max_wait_timeout`, `interactive_timeout`, `net_read_timeout`), превышение `max_allowed_packet`, сетевые проблемы, превышение буфера кэша (обычно `net_buffer_length` или `innodb_buffer_pool_size`, но это зависит от драйвера таблицы)  
Можно получить дополнительную информацию о потерянных соединениях, запустив mysql с опцией `--log-warnings=2`. Это регистрирует некоторые отключенные ошибки в файле hostname.err.   

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

---

Когда у сервера или процесса заканчивается память, Linux предлагает 2 пути решения: обрушить всю систему или завершить процесс (приложение), который съедает память. Лучше, конечно, завершить процесс и спасти ОС от аварийного завершения. `Out-Of-Memory Killer` — это процесс, который завершает приложение, чтобы спасти ядро от сбоя. Он жертвует приложением, чтобы сохранить работу ОС.  
Чтобы не приходилось использовать OOM-Killer для завершения PostgreSQL, можно установить для vm.overcommit_memory значение 2. Это не гарантирует, что OOM-Killer не придется вмешиваться, но снизит вероятность принудительного завершения процесса PostgreSQL.

Значения:

```yaml
0: ядро само решает, стоит ли резервировать слишком много памяти. Это значение по умолчанию в большинстве версий Linux.
1: ядро всегда будет резервировать лишнюю память. Это рискованно, ведь память может закончиться, потому что, скорее всего, однажды процессы затребуют положенное.
2: ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio.
```


---